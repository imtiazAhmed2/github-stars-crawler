name: Crawl GitHub Stars (Node.js)

on:
  workflow_dispatch:
  schedule:
    - cron: '0 3 * * *'  # daily at 03:00 UTC

jobs:
  crawl:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: github_data
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U postgres"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install deps
        run: npm ci

      - name: Wait for Postgres
        run: |
          for i in $(seq 1 30); do
            pg_isready -h localhost -p 5432 -U postgres && break
            echo "waiting for postgres..."
            sleep 2
          done

      - name: Apply schema
        env:
          PGPASSWORD: postgres
        run: |
          psql -h localhost -U postgres -d github_data -f schema.sql

      - name: Run crawler
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          DB_HOST: localhost
          DB_USER: postgres
          DB_PASS: postgres
          DB_NAME: github_data
        run: |
          node crawl_stars.js --target=100000

      - name: Export repositories CSV
        env:
          PGPASSWORD: postgres
        run: |
          mkdir -p artifacts
          psql -h localhost -U postgres -d github_data -c "\copy (SELECT * FROM repositories) TO 'artifacts/repositories.csv' CSV HEADER"

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: gh-repos
          path: artifacts/*.csv
